# ğŸ”¥ FireWatch AI â€“ Backend IoT e Inteligencia Artificial

Proyecto Final â€“ Internet de las Cosas (IoT)  
Universidad Nacional de San AgustÃ­n de Arequipa (UNSA)  
Diciembre 2025  

---

## ğŸ“Œ DescripciÃ³n de este repositorio

Este repositorio implementa la **capa central de procesamiento inteligente del sistema FireWatch AI**, encargada de la recepciÃ³n de eventos IoT, el procesamiento de informaciÃ³n multimedia y la ejecuciÃ³n de inferencia mediante modelos de Inteligencia Artificial.

El mÃ³dulo desarrollado integra mensajerÃ­a IoT, servicios backend y visualizaciÃ³n web, permitiendo la **detecciÃ³n temprana de incendios** y la clasificaciÃ³n automÃ¡tica de eventos segÃºn su nivel de riesgo.

Este repositorio corresponde **Ãºnicamente** a la capa de Backend IoT + IA del proyecto general.

---

## ğŸ¯ Rol dentro del proyecto FireWatch AI

Este mÃ³dulo se encarga especÃ­ficamente de:

- Recibir eventos desde el sistema IoT mediante MQTT  
- Descargar imÃ¡genes asociadas a los eventos detectados  
- Ejecutar inferencia con un modelo de Deep Learning  
- Clasificar el evento como:
  - NORMAL
  - RIESGO
  - CONFIRMADO  
- Exponer resultados mediante endpoints REST  
- Proveer informaciÃ³n procesada al dashboard web  

Otros componentes del sistema (firmware IoT, aplicaciÃ³n mÃ³vil, broker MQTT e infraestructura) se desarrollan y documentan en repositorios independientes.

---

## ğŸ§  TecnologÃ­as utilizadas

- Python 3.10+
- FastAPI
- MQTT (HiveMQ)
- PyTorch
- Streamlit
- Docker
- Google Cloud Storage

---

## ğŸ“‚ Estructura del Proyecto

```text
MODELOIA-IOT/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ container.py          # Instancia global del servicio de inferencia
â”‚   â”œâ”€â”€ gcs_client.py         # Cliente de Google Cloud Storage
â”‚   â”œâ”€â”€ image_downloader.py   # Descarga persistente de imÃ¡genes
â”‚   â”œâ”€â”€ image_model.py        # Modelo CNN (EfficientNet)
â”‚   â”œâ”€â”€ inference.py          # LÃ³gica de inferencia con IA
â”‚   â”œâ”€â”€ main.py               # Backend FastAPI
â”‚   â”œâ”€â”€ mqtt_listener.py      # Listener MQTT (HiveMQ)
â”‚   â””â”€â”€ settings.py           # ConfiguraciÃ³n general del sistema
â”‚
â”œâ”€â”€ downloaded_images/        # ImÃ¡genes descargadas y analizadas
â”œâ”€â”€ models/
â”‚   â””â”€â”€ image_fire.pt         # Pesos del modelo entrenado
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ train_image.py        # Script de entrenamiento del modelo
â”œâ”€â”€ dashboard.py              # Dashboard web (Streamlit)
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â””â”€â”€ README.md
```

---

## ğŸ”Œ Endpoints REST implementados

### GET /health

Permite verificar el estado del backend IoT.

Respuesta esperada:
```json
{
  "status": "ok"
}
```


---


### POST /predict

Ejecuta la inferencia del modelo de Inteligencia Artificial sobre una imagen almacenada.

Request:
```json
{
  "image_blob": "test.jpeg",
  "use_latest_if_missing": false
}
```

Response:
```json
{
  "status": "FIRE",
  "final_score": 0.80,
  "image_probability": 1.0,
  "confidence": 0.95
}
```
Este endpoint es utilizado tanto por el flujo IoT como por el dashboard web.

---



## â–¶ï¸ EjecuciÃ³n del proyecto en entorno local

### 1. Clonar el repositorio

```bash
git clone https://github.com/usuario/firewatch-ai-backend.git
cd MODELOIA-IOT
```

### 2. Crear y activar entorno virtual
Crear el entorno virtual:
```bash
python -m venv venv
```
Activar el entorno virtual:

#### Windows
```bash
venv\Scripts\activate
```
#### Linux / macOS
```bash
source venv/bin/activate
```




### 3. Instalar dependencias
```bash
pip install -r requirements.txt
```


### 4. Configurar variables de entorno
Crear el archivo .env en la raÃ­z del proyecto con el siguiente contenido:

```bash
MQTT_BROKER_URL=broker.hivemq.com
MQTT_TOPIC=pic
GCS_BUCKET_NAME=firewatch-images
GOOGLE_APPLICATION_CREDENTIALS=secrets/service_account.json

```


### 5. Ejecutar el backend IoT

```bash
uvicorn app.main:app --host 0.0.0.0 --port 8000
```
El backend quedarÃ¡ disponible en:
```bash
http://localhost:8000
```


### 6. Ejecutar el dashboard web
En una nueva terminal (con el entorno virtual activo):
```bash
streamlit run dashboard.py

```
El dashboard estarÃ¡ disponible en:

```bash
http://localhost:8501
```







